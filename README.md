# _SonoNet_ - IRC Classification Project
**Classification of benign/malignant tumours from medical images (breast ultrasound).**

## Goal
Build a **reproducible** ML pipeline to classify **benign vs malignant** tumours, with honest evaluation (patient-level splits where applicable).

## Datasets
  - **BUS-BRA (primary)** - 1875 images / 1064 patients, BI-RADS + tumour delineations. **CC BY 4.0**
  Links: https://github.com/wgomezf/BUS-BRA | https://zenodo.org/records/8231412
- **BUS-UCLM (extension: cross-dataset generalisation)** - 683 images / 38 patients, normal/benign/malignant + masks. **CC BY 4.0**
  Links: https://github.com/noeliavallez/BUS-UCLM-Dataset

## Approach (preliminary)
- Baseline: transfer learning CNN (ResNet18, EfficientNet-B0, DenseNet121)
- ViT backbones: DINOv2 (Base / Large) and CLIP via HuggingFace
- Mask-aware (extension): ROI-cropped classification (ROI-only vs ROI+context)
- Evaluation: ROC-AUC/PR-AUC/F1 + confusion matrix (focus on malignant recall)

## Repo structure
```
irc-classification-project/
â”œâ”€â”€ pyproject.toml          # Dependencies + uv config
â”œâ”€â”€ .gitignore              # Data, checkpoints, envs excluded
â”œâ”€â”€ README.md               # Setup instructions, usage guide
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ sanity_dataloader.py  # âœ… Verify batch shapes/dtypes for any backbone
â”œâ”€â”€ src/busbra/
â”‚   â”œâ”€â”€ train.py            # Training loop with early stopping (empty)
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ prepare_data.py   # âœ… Load CSVs, create patient-level splits
â”‚   â”‚   â”œâ”€â”€ dataset.py        # âœ… Model-agnostic PyTorch Dataset (returns PIL.Image)
â”‚   â”‚   â”œâ”€â”€ preprocessing.py  # âœ… Backbone-specific preprocessing registry
â”‚   â”‚   â””â”€â”€ loaders.py        # âœ… Collate functions + DataLoader factory
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ model.py        # CNN model (empty)
â”‚   â””â”€â”€ evaluation/
â”‚       â””â”€â”€ evaluate.py     # (empty)
â””â”€â”€ data/
    â”œâ”€â”€ raw/            â† ğŸš¨ put dataset (BUS-BRA) here
    â”‚   â”œâ”€â”€ bus_data.csv
    â”‚   â”œâ”€â”€ bus_0001-l.png
    â”‚   â””â”€â”€ ...
    â””â”€â”€ splits/         â† âœ… created by prepare_data.py
        â”œâ”€â”€ patient_splits.csv  # patient ID + split assignment (for auditing)
        â”œâ”€â”€ split_info.json     # split metadata
        â””â”€â”€ splits.csv          # ID + Case + label + split (primary file used downstream)
```

## Data pipeline

The data pipeline is **model-agnostic**: the `BUSBRADataset` returns raw `PIL.Image` objects and metadata, and all backbone-specific preprocessing (resize, normalize, augment) is applied at DataLoader collation time.

### Supported backbones (`model_key`)

| `model_key` | Backbone | Preprocessing | Train augmentation |
|---|---|---|---|
| `imagenet_cnn` | ResNet18, EfficientNet-B0, DenseNet121 | Letterbox â†’ ImageNet norm | Flip, rotate Â±15Â°, brightness |
| `clip` | CLIP ViT (`openai/clip-vit-base-patch32`) | HuggingFace `CLIPProcessor` | Horizontal flip |
| `dinov2` | DINOv2 Base (`facebook/dinov2-base`) | HuggingFace `AutoImageProcessor` | None |
| `dinov3` | DINOv2 Large (`facebook/dinov2-large`) | HuggingFace `AutoImageProcessor` | None |

### Creating DataLoaders

```python
from busbra.data.loaders import create_dataloaders

train_loader, val_loader, test_loader = create_dataloaders(
    split_file="data/splits/splits.csv",
    images_dir="data/raw",
    model_key="imagenet_cnn",   # or "clip", "dinov2", "dinov3"
    batch_size=32,
    num_workers=4,
    size=224,
)

for batch in train_loader:
    images = batch["image"]     # (B, 3, H, W) float32
    labels = batch["label"]     # (B, 1)       float32
    cases  = batch["case"]      # list[str] â€” patient IDs
    ids    = batch["image_id"]  # list[str] â€” image filenames
```

### Sanity-checking the pipeline

```bash
# ImageNet CNN (no HuggingFace download required)
uv run python scripts/sanity_dataloader.py --model_key imagenet_cnn \
  --split_file data/splits/splits.csv \
  --images_dir data/raw

# CLIP (downloads ~1 GB checkpoint on first run, cached afterward)
uv run python scripts/sanity_dataloader.py --model_key clip \
  --split_file data/splits/splits.csv \
  --images_dir data/raw

# DINOv2 (downloads ~300 MB checkpoint on first run, cached afterward)
uv run python scripts/sanity_dataloader.py --model_key dinov2 \
  --split_file data/splits/splits.csv \
  --images_dir data/raw
```

Expected output for each split:
```
[train]
  image  shape=(4, 3, 224, 224)  dtype=torch.float32  min=-2.118  max=2.640
  label  shape=(4, 1)  dtype=torch.float32  unique=[0.0, 1.0]
  case   type=list  len=4  example='42'
  id     type=list  len=4   example='bus_0042-l'
  âœ“ assertions passed
```

## Setup
### 1) Clone repository
```bash
git clone https://github.com/HarryR8/irc-classification-project.git
cd irc-classification-project
```
### 2) Install `uv` package & project manager (one-time)
```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```
### 3) Create virtual environment + install dependencies
```bash
uv sync
```

## Usage
### 1) Activate the venv
```bash
# macOS/Linux:
source .venv/bin/activate

# Windows (PowerShell):
# .\.venv\Scripts\Activate.ps1
```
### 2) Prepare data splits
```bash
uv run python -m busbra.data.prepare_data
```
### 3) Verify the pipeline
```bash
uv run python scripts/sanity_dataloader.py --model_key imagenet_cnn \
  --split_file data/splits/splits.csv \
  --images_dir data/raw
```

## Team
Zhuo Jin â€¢ Charlie Lam â€¢ Harry Reeve â€¢ Karolina Zvonickova (Advisor: James DesLauriers)

## Reference
GÃ³mez-Flores et al. (2024). BUS-BRA: A Breast Ultrasound Dataset for Assessing CAD Systems. *Medical Physics*, 51(4), 3110-3123.

## License
MIT
