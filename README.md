# _SonoNet_ - IRC Classification Project
**Classification of benign/malignant tumours from medical images (breast ultrasound).**

## Goal
Build a **reproducible** ML pipeline to classify **benign vs malignant** tumours, with honest evaluation (patient-level splits where applicable).

## Datasets
  - **BUS-BRA (primary)** - 1875 images / 1064 patients, BI-RADS + tumour delineations. **CC BY 4.0**
  Links: https://github.com/wgomezf/BUS-BRA | https://zenodo.org/records/8231412
- **BUS-UCLM (extension: cross-dataset generalisation)** - 683 images / 38 patients, normal/benign/malignant + masks. **CC BY 4.0**
  Links: https://github.com/noeliavallez/BUS-UCLM-Dataset

## Approach (preliminary)
- Baseline: transfer learning CNN (ResNet18, EfficientNet-B0, DenseNet121)
- ViT backbones: DINOv2 (Base / Large) and CLIP via HuggingFace
- Mask-aware (extension): ROI-cropped classification (ROI-only vs ROI+context)
- Evaluation: ROC-AUC/PR-AUC/F1 + confusion matrix (focus on malignant recall)

## Repo structure
```
irc-classification-project/
â”œâ”€â”€ pyproject.toml          # Dependencies + uv config
â”œâ”€â”€ .gitignore              # Data, checkpoints, envs excluded
â”œâ”€â”€ README.md               # Setup instructions, usage guide
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ sanity_dataloader.py  # âœ… Verify batch shapes/dtypes for any backbone
â”œâ”€â”€ src/busbra/
â”‚   â”œâ”€â”€ train.py            # Training loop with early stopping (empty)
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ prepare_data.py   # âœ… Load CSVs, create patient-level splits
â”‚   â”‚   â”œâ”€â”€ dataset.py        # âœ… Model-agnostic PyTorch Dataset (returns PIL.Image)
â”‚   â”‚   â”œâ”€â”€ preprocessing.py  # âœ… Backbone-specific preprocessing registry
â”‚   â”‚   â””â”€â”€ loaders.py        # âœ… Collate functions + DataLoader factory
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ factory.py        # âœ… Model registry + create_model / create_backbone
â”‚   â”‚   â”œâ”€â”€ heads.py          # âœ… Classification head architectures (linear, mlp, mlp_deep)
â”‚   â”‚   â””â”€â”€ __init__.py       # âœ… Public exports
â”‚   â””â”€â”€ evaluation/
â”‚       â””â”€â”€ evaluate.py     # (empty)
â””â”€â”€ data/
    â”œâ”€â”€ raw/            â† ğŸš¨ put dataset (BUS-BRA) here
    â”‚   â”œâ”€â”€ bus_data.csv
    â”‚   â”œâ”€â”€ bus_0001-l.png
    â”‚   â””â”€â”€ ...
    â””â”€â”€ splits/         â† âœ… created by prepare_data.py
        â”œâ”€â”€ patient_splits.csv  # patient ID + split assignment (for auditing)
        â”œâ”€â”€ split_info.json     # split metadata
        â””â”€â”€ splits.csv          # ID + Case + label + split (primary file used downstream)
```

## Data pipeline

The data pipeline is **model-agnostic**: the `BUSBRADataset` returns raw `PIL.Image` objects and metadata, and all backbone-specific preprocessing (resize, normalize, augment) is applied at DataLoader collation time.

### Supported backbones (`model_key`)

| `model_key` | Backbone | Preprocessing | Train augmentation |
|---|---|---|---|
| `imagenet_cnn` | ResNet18, EfficientNet-B0, DenseNet121 | Letterbox â†’ ImageNet norm | Flip, rotate Â±15Â°, brightness |
| `clip` | CLIP ViT (`openai/clip-vit-base-patch32`) | HuggingFace `CLIPProcessor` | Horizontal flip |
| `dinov2` | DINOv2 Base (`facebook/dinov2-base`) | HuggingFace `AutoImageProcessor` | None |
| `dinov3` | DINOv2 Large (`facebook/dinov2-large`) | HuggingFace `AutoImageProcessor` | None |

### Creating DataLoaders

```python
from busbra.data.loaders import create_dataloaders

train_loader, val_loader, test_loader = create_dataloaders(
    split_file="data/splits/splits.csv",
    images_dir="data/raw",
    model_key="imagenet_cnn",   # or "clip", "dinov2", "dinov3"
    batch_size=32,
    num_workers=4,
    size=224,
)

for batch in train_loader:
    images = batch["image"]     # (B, 3, H, W) float32
    labels = batch["label"]     # (B, 1)       float32
    cases  = batch["case"]      # list[str] â€” patient IDs
    ids    = batch["image_id"]  # list[str] â€” image filenames
```

### Sanity-checking the pipeline

```bash
# ImageNet CNN (no HuggingFace download required)
uv run python scripts/sanity_dataloader.py --model_key imagenet_cnn \
  --split_file data/splits/splits.csv \
  --images_dir data/raw

# CLIP (downloads ~1 GB checkpoint on first run, cached afterward)
uv run python scripts/sanity_dataloader.py --model_key clip \
  --split_file data/splits/splits.csv \
  --images_dir data/raw

# DINOv2 (downloads ~300 MB checkpoint on first run, cached afterward)
uv run python scripts/sanity_dataloader.py --model_key dinov2 \
  --split_file data/splits/splits.csv \
  --images_dir data/raw
```

Expected output for each split:
```
[train]
  image  shape=(4, 3, 224, 224)  dtype=torch.float32  min=-2.118  max=2.640
  label  shape=(4, 1)  dtype=torch.float32  unique=[0.0, 1.0]
  case   type=list  len=4  example='42'
  id     type=list  len=4   example='bus_0042-l'
  âœ“ assertions passed
```

## Model factory

The model factory (`busbra.models`) provides a consistent interface for creating classifiers, with support for three transfer learning modes.

### Model registry

| Model name | Backbone | `preprocess_key` | Embed dim | Status |
|---|---|---|---|---|
| `resnet18` | ResNet-18 | `imagenet_cnn` | 512 | âœ… |
| `resnet50` | ResNet-50 | `imagenet_cnn` | 2048 | âœ… |
| `efficientnet_b0` | EfficientNet-B0 | `imagenet_cnn` | 1280 | âœ… |
| `densenet121` | DenseNet-121 | `imagenet_cnn` | 1024 | âœ… |
| `dinov2_base` | DINOv2 Base | `dinov2` | 768 | ğŸ”œ planned |
| `clip_vit_base` | CLIP ViT-B/32 | `clip` | 512 | ğŸ”œ planned |

### Usage modes

```python
from busbra.models import create_model, create_backbone, get_preprocess_key, count_parameters

# 1. Full fine-tuning â€” all ~11 M params trainable
model = create_model("resnet18", num_classes=2, pretrained=True)

# 2. Frozen backbone + custom head â€” only head params trainable
model = create_model(
    "resnet18",
    freeze_backbone=True,
    head_type="mlp",        # "linear" | "mlp" | "mlp_deep"
    head_hidden_dim=256,
    head_dropout=0.3,
)
print(count_parameters(model))
# {'total': 11308354, 'trainable': 131842, 'frozen': 11176512}

# 3. Backbone only â€” for pre-computing and caching embeddings
backbone, embed_dim = create_backbone("resnet18", pretrained=True)
backbone.eval()
with torch.no_grad():
    features = backbone(images)  # (B, 512)

# Link model name â†’ preprocessing key for DataLoader
preprocess_key = get_preprocess_key("resnet18")  # "imagenet_cnn"
```

### Classification heads

| `head_type` | Architecture | Trainable params (resnet18 backbone) |
|---|---|---|
| `linear` | `Linear(512 â†’ 2)` | 1,026 |
| `mlp` | `Linear â†’ ReLU â†’ Dropout â†’ Linear` | 131,842 |
| `mlp_deep` | `Linear â†’ ReLU â†’ Dropout â†’ Linear â†’ ReLU â†’ Dropout â†’ Linear` | 164,482 |

## Setup
### 1) Clone repository
```bash
git clone https://github.com/HarryR8/irc-classification-project.git
cd irc-classification-project
```
### 2) Install `uv` package & project manager (one-time)
```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```
### 3) Create virtual environment + install dependencies
```bash
uv sync
```

## Usage
### 1) Activate the venv
```bash
# macOS/Linux:
source .venv/bin/activate

# Windows (PowerShell):
# .\.venv\Scripts\Activate.ps1
```
### 2) Prepare data splits
```bash
uv run python -m busbra.data.prepare_data
```
### 3) Verify the pipeline
```bash
uv run python scripts/sanity_dataloader.py --model_key imagenet_cnn \
  --split_file data/splits/splits.csv \
  --images_dir data/raw
```

## Team
Zhuo Jin â€¢ Charlie Lam â€¢ Harry Reeve â€¢ Karolina Zvonickova (Advisor: Jay DesLauriers)

## Reference
GÃ³mez-Flores et al. (2024). BUS-BRA: A Breast Ultrasound Dataset for Assessing CAD Systems. *Medical Physics*, 51(4), 3110-3123.

## License
MIT
